# eval tasks go to `output/eval` by default
label: eval

# ADT Evaluation Configuration
eval:

  # limit to only this many tests per task
  limit: 10

  # our rate limit (per minute) on calls to the LLM
  rate_limit: 300

  # Tasks to run (empty list means run all available tasks)
  tasks_to_run: []

  # Task-specific configurations
  tasks:
    text_extraction:
      label_studio_project_name: "A2: Text Type"
      model: ${default_model}
      prompt: ${prompts.text_extraction}
      report_template_path: templates/eval/text_extraction_report.html